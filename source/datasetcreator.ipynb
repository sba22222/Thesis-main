{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04abc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original License:\n",
    "# Copyright 2021 Tristan Behrens.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Lint as: python3\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from music21.stream import Score\n",
    "\n",
    "from source import logging\n",
    "from source.preprocess.music21lmd import preprocess_music21\n",
    "from source.preprocess.encode import get_density_bins, encode_songs_data\n",
    "\n",
    "logger = logging.create_logger(\"datasetcreator\")\n",
    "\n",
    "\n",
    "class DatasetCreator:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "\n",
    "    def create(\n",
    "        self,\n",
    "        dataset_path: Path,\n",
    "        m21_streams: List[Score],\n",
    "        current_iteration: int,\n",
    "        overwrite=False,\n",
    "    ) -> None:\n",
    "        # Make sure the dataset_path exists\n",
    "        if not os.path.exists(dataset_path):\n",
    "            os.mkdir(dataset_path)\n",
    "\n",
    "        # Make sure that path for this specific dataset exists\n",
    "        dataset_path = os.path.join(dataset_path, self.config.dataset_name)\n",
    "        if os.path.exists(dataset_path) and overwrite is False:\n",
    "            logger.info(\"Dataset already exists.\")\n",
    "            return\n",
    "        if not os.path.exists(dataset_path):\n",
    "            os.makedirs(dataset_path)\n",
    "\n",
    "        # Prepare for getting music data as json\n",
    "        json_data_method = None\n",
    "        if self.config.json_data_method == \"preprocess_music21\":\n",
    "            json_data_method = preprocess_music21\n",
    "        elif callable(self.config.json_data_method):\n",
    "            json_data_method = self.config.json_data_method\n",
    "        else:\n",
    "            error_string = f\"Unexpected {self.config.json_data_method}\"\n",
    "            logger.error(error_string)\n",
    "            raise Exception(error_string)\n",
    "\n",
    "        # Get music data as json\n",
    "        songs_data_train, songs_data_valid = json_data_method(m21_streams)\n",
    "\n",
    "        # Get density bins\n",
    "        density_bins = get_density_bins(\n",
    "            songs_data_train,\n",
    "            self.config.window_size_bars,\n",
    "            self.config.hop_length_bars,\n",
    "            self.config.density_bins_number,\n",
    "        )\n",
    "\n",
    "        # Process and save training data\n",
    "        token_sequences_train = encode_songs_data(\n",
    "            songs_data_train,\n",
    "            transpositions=self.config.transpositions_train,\n",
    "            permute=self.config.permute_tracks,\n",
    "            window_size_bars=self.config.window_size_bars,\n",
    "            hop_length_bars=self.config.hop_length_bars,\n",
    "            density_bins=density_bins,\n",
    "            bar_fill=self.config.encoding_method == \"mmmbar\",\n",
    "        )\n",
    "\n",
    "        dataset_path_train = os.path.join(\n",
    "            dataset_path, f\"token_sequences_train_{current_iteration}.txt\"\n",
    "        )\n",
    "        self.__save_token_sequences(token_sequences_train, dataset_path_train)\n",
    "        logger.info(f\"Saved training data to {dataset_path_train}\")\n",
    "\n",
    "        # Process and save validation data\n",
    "        token_sequences_valid = encode_songs_data(\n",
    "            songs_data_valid,\n",
    "            transpositions=[0],\n",
    "            permute=self.config.permute_tracks,\n",
    "            window_size_bars=self.config.window_size_bars,\n",
    "            hop_length_bars=self.config.hop_length_bars,\n",
    "            density_bins=density_bins,\n",
    "            bar_fill=self.config.encoding_method == \"mmmbar\",\n",
    "        )\n",
    "\n",
    "        dataset_path_valid = os.path.join(\n",
    "            dataset_path, f\"token_sequences_valid_{current_iteration}.txt\"\n",
    "        )\n",
    "        self.__save_token_sequences(token_sequences_valid, dataset_path_valid)\n",
    "        logger.info(f\"Saved validation data to {dataset_path_valid}\")\n",
    "\n",
    "    def __save_token_sequences(self, token_sequences, path):\n",
    "        with open(path, \"w\") as file:\n",
    "            for token_sequence in token_sequences:\n",
    "                print(\" \".join(token_sequence), file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
