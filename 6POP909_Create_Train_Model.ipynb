{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-JPBj2w9XeK"
   },
   "source": [
    "# Training a GPT-2 Language Model on the POP909 Dataset\n",
    "\n",
    "The below script is dedicated to training a language model on the POP909 dataset using the GPT-2 architecture. It begins by installing necessary libraries and importing required modules. Then it loads the preprocessed dataset and tokenizes it using the Hugging Face tokenizer.\n",
    "\n",
    "The script proceeds to define the GPT-2 model architecture and configure it based on specified parameters such as the number of layers, attention heads, and embedding dimension. It calculates and prints the size of the GPT-2 model in terms of parameters.\n",
    "\n",
    "Next, it prepares the data for training by creating a data collator that handles batch preparation and creates language model labels. It applies the data collator to a small subset of the training data to verify its functionality.\n",
    "\n",
    "The script then sets up the training environment, including logging configurations for Weights & Biases (WandB) integration and Hugging Face Hub login. It defines a custom trainer class that extends the Trainer class provided by the transformers library. This custom trainer includes additional functionality to log prediction distributions during evaluation.\n",
    "\n",
    "Training hyperparameters and configuration parameters are defined, and a WandB run is initiated to monitor training progress and log metrics.\n",
    "\n",
    "The model training loop is executed using the Trainer object, which handles training epochs, batch processing, and evaluation. During evaluation, the custom trainer logs generated audio samples for qualitative analysis.\n",
    "\n",
    "Once training is complete, the WandB run is finished, and the model checkpoint is saved to the specified output directory. Overall, this notebook provides a comprehensive pipeline for training a GPT-2 language model on the POP909 dataset, including data preprocessing, model setup, training, and result logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfKrOGIuA-8l",
    "outputId": "4e8c312e-4bab-4856-dcc2-5207423eecef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8\n"
     ]
    }
   ],
   "source": [
    "import locale\n",
    "print(locale.getpreferredencoding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uwJjLj4XA-8l"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPGNyAscsvzD",
    "outputId": "777d7540-7985-48f6-ba37-21b750e267d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf==4.21.2 in /usr/local/lib/python3.10/dist-packages (4.21.2)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.16.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.41)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.40.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.21.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: note_seq in /usr/local/lib/python3.10/dist-packages (0.0.5)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from note_seq) (1.4.0)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from note_seq) (23.2.0)\n",
      "Requirement already satisfied: bokeh>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from note_seq) (3.3.4)\n",
      "Requirement already satisfied: intervaltree>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from note_seq) (3.1.0)\n",
      "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (from note_seq) (7.34.0)\n",
      "Requirement already satisfied: librosa>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from note_seq) (0.10.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from note_seq) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from note_seq) (1.5.3)\n",
      "Requirement already satisfied: pretty-midi>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from note_seq) (0.2.10)\n",
      "Requirement already satisfied: protobuf>=4.21.2 in /usr/local/lib/python3.10/dist-packages (from note_seq) (4.21.2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from note_seq) (0.25.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.10/dist-packages (from note_seq) (1.11.4)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh>=0.12.0->note_seq) (3.1.3)\n",
      "Requirement already satisfied: contourpy>=1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=0.12.0->note_seq) (1.2.0)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh>=0.12.0->note_seq) (23.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=0.12.0->note_seq) (9.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh>=0.12.0->note_seq) (6.0.1)\n",
      "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=0.12.0->note_seq) (6.3.2)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=0.12.0->note_seq) (2023.10.1)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=2.1.0->note_seq) (2.4.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (3.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (0.58.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (1.8.0)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (4.9.0)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.2->note_seq) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.1->note_seq) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18.1->note_seq) (2023.4)\n",
      "Requirement already satisfied: mido>=1.1.16 in /usr/local/lib/python3.10/dist-packages (from pretty-midi>=0.2.6->note_seq) (1.3.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from pretty-midi>=0.2.6->note_seq) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (67.7.2)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (0.19.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (5.7.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (3.0.43)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (2.16.1)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython->note_seq) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython->note_seq) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh>=0.12.0->note_seq) (2.1.5)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.6.2->note_seq) (0.41.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython->note_seq) (0.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.6.2->note_seq) (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.6.2->note_seq) (2.31.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->note_seq) (0.2.13)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa>=0.6.2->note_seq) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa>=0.6.2->note_seq) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.6.2->note_seq) (2.21)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.2->note_seq) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.2->note_seq) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.2->note_seq) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.6.2->note_seq) (2024.2.2)\n",
      "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.26.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.3)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.26.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -U protobuf==4.21.2\n",
    "!pip install datasets\n",
    "!pip install wandb\n",
    "!pip install note_seq\n",
    "!pip install transformers[torch]\n",
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dcjc3NRIA-8m",
    "outputId": "ee0e354d-d8ed-4627-832f-c4bd4fb02086"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing dependencies...\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "fluidsynth is already the newest version (2.2.5-1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Check if the code is running in Google Colab environment\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "    # Inform the user about installing dependencies in Colab\n",
    "    print(\"Installing dependencies...\")\n",
    "\n",
    "    # Install fluidsynth and its development libraries using pip\n",
    "    !apt-get install fluidsynth\n",
    "    !apt-get install -qq libasound2-dev libjack-dev\n",
    "\n",
    "    # Install the pyfluidsynth library using pip\n",
    "    !pip install -qU pyfluidsynth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "SvKeVNjPA-8m"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import note_seq\n",
    "import numpy as np\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import AutoTokenizer, AutoConfig, GPT2LMHeadModel, DataCollatorForLanguageModeling, set_seed, Trainer, TrainingArguments\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "COgCtDY2bJpQ"
   },
   "outputs": [],
   "source": [
    "# Set the Protocol Buffers Python implementation to \"python\"\n",
    "# This line is used to resolve compatibility issues related to Protocol Buffers (protobuf)\n",
    "# It explicitly selects the pure Python implementation of the protobuf library\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NlnpAb2JA-8n"
   },
   "outputs": [],
   "source": [
    "# Set parameters for WandB (Weights & Biases) integration\n",
    "wandb_project = \"pop909_musicgen\"\n",
    "entity = \"musicgen\"\n",
    "data_processed = \"pop909_processed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4vQF0ZdtPzP"
   },
   "source": [
    "## Download Dataset and tokenizer from Hugging Face\n",
    "\n",
    "In the pretokenization notebook, we trained a tokenizer. We'll use it here first to do some basic EDA to understand our data and what type of model size is better (number of layers, heads, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Se37G7o30ap",
    "outputId": "47a0cadd-928d-4cfa-9ed9-c62159be5ef4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 29930\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3326\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a dataset named \"aimusicgen/pop909_clean_data\" using the Hugging Face datasets library\n",
    "# The split parameter is set to \"train\" to load the training split of the dataset\n",
    "ds = load_dataset(\"aimusicgen/pop909_clean_data\", split=\"train\")\n",
    "\n",
    "# Split the loaded dataset into training and testing sets using train_test_split method\n",
    "# The test_size parameter specifies the fraction of the dataset to include in the test split (here, 10%)\n",
    "# The shuffle parameter is set to True to shuffle the data before splitting\n",
    "raw_datasets = ds.train_test_split(test_size=0.1, shuffle=True)\n",
    "\n",
    "# Instantiate a tokenizer using the AutoTokenizer class from the transformers library\n",
    "# The \"tokenizer\" argument is the pretrained tokenizer from the previous notebook\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"aimusicgen/pop909_tokenizer\")\n",
    "\n",
    "# Display the raw datasets, which now include both training and testing splits\n",
    "# The raw_datasets variable now contains a tuple with two elements: training and testing datasets\n",
    "raw_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUPZXE0NA-8n"
   },
   "source": [
    "### Why is the data suffled before it is split into training and testing?\n",
    "\n",
    "The data is suffled to help introduce **randomness** into the data. This is important because it prevents any inherent order in the dataset from influencing the learning algorithm. If the data is ordered in a certain way (e.g., all samples of one class followed by another), shuffling helps ensure that the model sees a representative mix of samples from all classes during both training and testing.\n",
    "\n",
    "Some algorithms might perform differently or learn **biased** patterns if trained on data with a specific order. By shuffling the data, you reduce the risk of the model learning patterns based on the order of the examples.\n",
    "\n",
    "Shuffling contributes to better **generalization** of the model. If the model is exposed to diverse examples during training (rather than learning specific patterns related to the order of the data), it is more likely to perform well on new, unseen data.\n",
    "\n",
    "When splitting a dataset into training and testing sets, shuffling ensures that both sets contain a representative mix of examples. This is important, especially in scenarios like **cross-validation**, where you repeatedly split the data into different training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cCxK_DEBREOs"
   },
   "outputs": [],
   "source": [
    "# Define the context length for tokenization\n",
    "# In this case, it is set to 512, meaning the input sequences will be truncated or padded to this length\n",
    "context_length = 512\n",
    "\n",
    "# Define a tokenization function named \"tokenize\" that takes an element as input\n",
    "def tokenize(element):\n",
    "    # Use the tokenizer to process the \"text\" field of the input element\n",
    "    # Set truncation to True to truncate sequences longer than the specified context length\n",
    "    # Set max_length to the context_length to ensure all sequences have the same length\n",
    "    # Set padding to False to avoid adding padding tokens to the sequences\n",
    "    outputs = tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        padding=False\n",
    "    )\n",
    "\n",
    "    # Return a dictionary containing the \"input_ids\" field from the tokenizer outputs\n",
    "    return {\"input_ids\": outputs[\"input_ids\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6rnVdV5mA-8o"
   },
   "outputs": [],
   "source": [
    "# Select an example from the training split of the raw dataset (index 1000)\n",
    "selected_example = raw_datasets[\"train\"][1000]\n",
    "\n",
    "# Tokenize the selected example using the tokenize function defined earlier\n",
    "# The tokenize function processes the \"text\" field of the input example\n",
    "# and returns a dictionary containing the \"input_ids\" field with tokenized representation\n",
    "tk_sample = tokenize(selected_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rtqnvDI6A-8o",
    "outputId": "68f838db-70e6-431b-8716-3da9271beb20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of tk_sample ids 512\n",
      "tk_sample {'input_ids': [100, 62, 60, 12, 9, 31, 6, 35, 13, 25, 8, 24, 6, 31, 17, 14, 30, 19, 5, 30, 7, 18, 6, 33, 14, 32, 6, 47, 8, 46, 10, 64, 8, 63, 7, 70, 8, 69, 13, 85, 7, 84, 9, 16, 9, 34, 11, 12, 9, 104, 7, 103, 14, 31, 9, 45, 13, 44, 64, 8, 19, 6, 30, 6, 63, 70, 45, 51, 13, 44, 6, 45, 17, 14, 44, 75, 69, 13, 16, 9, 50, 9, 18, 11, 12, 9, 19, 45, 13, 18, 44, 6, 64, 19, 13, 18, 63, 64, 49, 15, 17, 7, 48, 8, 49, 14, 16, 10, 48, 63, 45, 47, 13, 46, 5, 44, 47, 19, 45, 51, 14, 18, 44, 6, 46, 45, 19, 45, 17, 8, 18, 44, 7, 44, 9, 50, 5, 16, 11, 12, 9, 45, 19, 45, 8, 18, 7, 44, 44, 19, 19, 13, 18, 49, 49, 5, 18, 13, 31, 10, 48, 8, 30, 6, 48, 47, 31, 13, 46, 6, 30, 49, 19, 13, 48, 5, 18, 33, 77, 33, 14, 32, 7, 33, 35, 14, 32, 75, 32, 10, 34, 9, 76, 11, 61, 62, 60, 12, 9, 31, 6, 35, 13, 25, 8, 24, 6, 31, 17, 14, 30, 19, 5, 30, 7, 18, 6, 33, 14, 32, 6, 47, 8, 46, 10, 64, 8, 63, 7, 70, 8, 69, 13, 85, 7, 84, 9, 16, 9, 34, 11, 12, 9, 104, 7, 103, 14, 31, 9, 45, 13, 44, 64, 8, 19, 6, 30, 6, 63, 70, 45, 51, 13, 44, 6, 45, 17, 14, 44, 75, 69, 13, 16, 9, 50, 9, 18, 11, 12, 9, 19, 45, 13, 18, 44, 6, 64, 19, 13, 18, 63, 64, 49, 15, 17, 7, 48, 8, 49, 14, 16, 10, 48, 63, 45, 47, 13, 46, 5, 44, 47, 19, 45, 51, 14, 18, 44, 6, 46, 45, 19, 45, 17, 8, 18, 44, 7, 44, 9, 50, 5, 16, 11, 12, 9, 45, 19, 45, 8, 18, 7, 44, 44, 19, 19, 13, 18, 49, 49, 5, 18, 13, 31, 10, 48, 8, 30, 6, 48, 47, 31, 13, 46, 6, 30, 49, 19, 13, 48, 5, 18, 33, 77, 33, 14, 32, 7, 33, 35, 14, 32, 75, 32, 10, 34, 9, 76, 11, 61, 62, 60, 12, 9, 31, 6, 35, 13, 25, 8, 24, 6, 31, 17, 14, 30, 19, 5, 30, 7, 18, 6, 33, 14, 32, 6, 47, 8, 46, 10, 64, 8, 63, 7, 70, 8, 69, 13, 85, 7, 84, 9, 16, 9, 34, 11, 12, 9, 104, 7, 103, 14, 31, 9, 45, 13, 44, 64, 8, 19, 6, 30, 6, 63, 70, 45, 51, 13, 44, 6, 45, 17, 14, 44, 75, 69, 13, 16, 9, 50, 9, 18, 11, 12, 9, 19, 45, 13, 18, 44, 6, 64, 19, 13, 18, 63, 64, 49, 15, 17, 7, 48, 8, 49, 14, 16, 10, 48, 63, 45, 47, 13, 46, 5, 44, 47, 19, 45, 51, 14, 18, 44, 6]}\n"
     ]
    }
   ],
   "source": [
    "# Print the length of the 'input_ids' field in the tokenized sample\n",
    "# This indicates the number of tokens in the tokenized representation of the input text\n",
    "print(f\"Len of tk_sample ids {len(tk_sample['input_ids'])}\")\n",
    "\n",
    "# Print the entire tokenized sample\n",
    "# The tokenized sample is a dictionary containing the 'input_ids' field\n",
    "print(f\"tk_sample {tk_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CsBNVmJgA-8o"
   },
   "source": [
    "As you can see only 742 tk_sample ids came back when there was an index of 1,000. This is possibly due to padding. It was set to *padding=False* in the *tokenize* function. Without padding, the resulting *input_ids* will not be padded to the maximum length, and if the original text is shorter than the specified *max_length*, the tokenized sequence will be shorter.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255,
     "referenced_widgets": [
      "3063bd81816b43139ab5899c7c31f2e3",
      "a7578b3f8cbd45fb9b0d28ec35fd63b9",
      "dae2d07d7e0c481a8add94341a848c12",
      "485f1e54e47342359653f7573c2a772b",
      "53eb9093a1754e789e43d911b102d57b",
      "bac6cd8567cb4938ad66eeadf511a5f6",
      "92c8b325541b463680d144974cf19568",
      "af8cfd94abbe44e0bf9a08e8951bc09e",
      "5b8bafc47b114271a198304adbcaba54",
      "e18c5d05563544c195ed935f55a4a5fb",
      "5e82d2d9b3c0431b8fdba40c2da0ca3d",
      "3ee28c7f4ce042bbb9086e67562f2c09",
      "b006ce4b6efd48f58793e0af42c9270b",
      "6b02d6ebfb894ceb86db9a2ed5715915",
      "5140065dbda3426c84ae7e999936a49a",
      "8778ca152a854fdda244f0960578b374",
      "6a9c6787fe01465b80e3e7017fba2088",
      "5e899760c10440ea9de2a6d06b3c1bf7",
      "92ed3298b39c4a7191e8fa5caa667c6d",
      "c82adea18c4f4364a1d686bd63f6b350",
      "ff7bf6f6de044496acc585244b8a1dd5",
      "9c6c00264ddf4446936058c232bad758"
     ]
    },
    "id": "4zunRo-CfEHr",
    "outputId": "acd06451-8944-49a6-e727-a2fb428b3f9c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3063bd81816b43139ab5899c7c31f2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/29930 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee28c7f4ce042bbb9086e67562f2c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3326 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 29930\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 3326\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the tokenize function to the entire raw dataset using the map method\n",
    "# The tokenize function is applied in a batched manner, improving efficiency\n",
    "# The remove_columns parameter is set to remove the columns from the raw dataset\n",
    "# (excluding the \"train\" split) after tokenization, as they are no longer needed\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize,                # The tokenization function to be applied\n",
    "    batched=True,            # Tokenize in batches for efficiency\n",
    "    remove_columns=raw_datasets[\"train\"].column_names  # Remove unnecessary columns after tokenization\n",
    ")\n",
    "\n",
    "# Display the resulting tokenized datasets\n",
    "# The tokenized_datasets variable now contains both training and testing splits with tokenized representations\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CICtm9YRkbgQ"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "S-3Bmvu1ihqA"
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters for model architecture\n",
    "# These parameters can be adjusted based on the size of the data and the specific requirements of the task\n",
    "\n",
    "n_layer = 6 # Number of layers in the transformer model\n",
    "n_head = 8 # Number of attention heads in each transformer layer\n",
    "n_emb = 512 # Dimensionality of the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OA1QEtv2lIX2"
   },
   "outputs": [],
   "source": [
    "# Use Hugging Face's AutoConfig to create a configuration for the GPT-2 model\n",
    "# The configuration is based on the \"gpt2\" pre-trained model, and some parameters are customized\n",
    "\n",
    "# Define the configuration using AutoConfig\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",                               # Base model: \"gpt2\"\n",
    "    vocab_size=len(tokenizer),            # Vocabulary size based on the tokenizer\n",
    "    n_positions=context_length,           # Maximum position embeddings (context length)\n",
    "    n_layer=n_layer,                      # Number of transformer layers\n",
    "    n_head=n_head,                        # Number of attention heads in each layer\n",
    "    pad_token_id=tokenizer.pad_token_id,  # ID of the padding token\n",
    "    bos_token_id=tokenizer.bos_token_id,  # ID of the beginning-of-sequence token\n",
    "    eos_token_id=tokenizer.eos_token_id,  # ID of the end-of-sequence token\n",
    "    n_embd=n_emb                           # Dimensionality of the embedding layer\n",
    ")\n",
    "\n",
    "# Create an instance of the GPT-2 language model using the configured parameters\n",
    "model = GPT2LMHeadModel(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zfi_c7Ijmjav",
    "outputId": "d7c1aacc-0aaa-4a8b-aab9-9722f2797230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 19.3M parameters\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the size of the GPT-2 model in terms of parameters\n",
    "# The size is measured in millions (M) of parameters\n",
    "\n",
    "# Calculate the total number of parameters in the GPT-2 model\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "\n",
    "# Print the size of the GPT-2 model in millions of parameters\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBfWG2iZBLop"
   },
   "source": [
    "Create a datacollator to will take care of preparing the data:\n",
    "\n",
    "\"Before we can start training, we need to set up a data collator that will take care of creating the batches. We can use the DataCollatorForLanguageModeling collator, which is designed specifically for language modeling (as the name subtly suggests). Besides stacking and padding batches, it also takes care of creating the language model labels — in causal language modeling the inputs serve as labels too (just shifted by one element), and this data collator creates them on the fly during training so we don’t need to duplicate the input_ids.\n",
    "\n",
    "Note that DataCollatorForLanguageModeling supports both masked language modeling (MLM) and causal language modeling (CLM). By default it prepares data for MLM, but we can switch to CLM by setting the argument mlm=False:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xGg8htNBnF_m"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KToTnxF8Ckkn",
    "outputId": "5db748e9-e03f-4abb-d9cb-803965848b21"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 512])\n",
      "attention_mask shape: torch.Size([5, 512])\n",
      "labels shape: torch.Size([5, 512])\n",
      "Collated outputs: {'input_ids': tensor([[100,  62,  60,  ...,   3,   3,   3],\n",
      "        [100,  62,  60,  ...,   3,   3,   3],\n",
      "        [100,  62,  60,  ...,   3,   3,   3],\n",
      "        [100,  62,  60,  ...,   3,   3,   3],\n",
      "        [100,  62,  60,  ...,  11,  12,   9]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[ 100,   62,   60,  ..., -100, -100, -100],\n",
      "        [ 100,   62,   60,  ..., -100, -100, -100],\n",
      "        [ 100,   62,   60,  ..., -100, -100, -100],\n",
      "        [ 100,   62,   60,  ..., -100, -100, -100],\n",
      "        [ 100,   62,   60,  ...,   11,   12,    9]])}\n"
     ]
    }
   ],
   "source": [
    "# Test the data collator on a small subset of the training data\n",
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "\n",
    "# Print the shapes of the collated outputs\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")\n",
    "\n",
    "# Display the collated outputs\n",
    "print(f\"Collated outputs: {out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OLNX31-WDMcX",
    "outputId": "12128575-9e36-41d2-d5f7-5462745454b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnaomitunstead\u001b[0m (\u001b[33mmusicgen\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login into wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MpkHZ6qO_Zt",
    "outputId": "b06f370b-5b3f-4596-d7fa-3ec0c8abe6a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_LOG_MODEL='checkpoint'\n"
     ]
    }
   ],
   "source": [
    "# Set the WandB environment variable to log the model checkpoint\n",
    "%env WANDB_LOG_MODEL='checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303,
     "referenced_widgets": [
      "f1d358fc8ef5420aa0b15a6511cb7931",
      "fd8318b4015244e3ad2ddea4f2deda7c",
      "6925f59ce901479ca15e50aee29f23ca",
      "920409b95bd543289b8ea0ea8f89473e",
      "35106fc0e5ca43a6a69381fb6547993b",
      "226e708fa1bd4216b218e28d7746e39e",
      "1bf77370a9004b98988b53b11e1831c8",
      "d31c9383bf7245999019beefa2030837",
      "f32ddb2204964815a878e06b76d11939",
      "d422ea1cf318479892f6c74022144dd0",
      "d48ab917e3dc4afd8207fc47691e4ef9",
      "7946aa749ef14a418851c1e7ba0fe71b",
      "905b6c619b8240afb69bc9004d824c0f",
      "46ab4365aafe4928bfafc46393f9110e",
      "8a94055a3fcd4d43847780e422b2c882",
      "6fd90eb4a07a430a96db8ec67ad1c739",
      "6e309afb004d4e1fb62f2070ac1f2595"
     ]
    },
    "id": "lyOSwB1dJHcW",
    "outputId": "6a36b7fb-60e3-43be-8d7f-be7195071752"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d358fc8ef5420aa0b15a6511cb7931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Login into Hugging Face\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ry-BYiGMJiq2"
   },
   "outputs": [],
   "source": [
    "# Create the args for out trainer\n",
    "\n",
    "# Get the output directory with timestamp.\n",
    "output_path = \"output\"\n",
    "steps = 350\n",
    "\n",
    "# Define training configuration parameters\n",
    "# Commented parameters correspond to the small model\n",
    "config = {\"output_dir\": output_path, # Specify the directory where output will be saved\n",
    "          \"num_train_epochs\": 1, # Number of epochs for training\n",
    "          \"per_device_train_batch_size\": 8, # Batch size for training on each device\n",
    "          \"per_device_eval_batch_size\": 4, # Batch size for evaluation on each device\n",
    "          \"evaluation_strategy\": \"steps\", # Strategy for evaluation during training (e.g., 'steps' means evaluate every certain number of steps)\n",
    "          \"save_strategy\": \"steps\",  # Strategy for saving checkpoints during training\n",
    "          \"eval_steps\": steps, # Number of steps before evaluation\n",
    "          \"logging_steps\":steps, # Number of steps before logging\n",
    "          \"logging_first_step\": True, # Log the first step\n",
    "          \"save_total_limit\": 5, # Limit on the total number of checkpoints to save\n",
    "          \"save_steps\": steps, # Number of steps before saving a checkpoint\n",
    "          \"lr_scheduler_type\": \"cosine\", # Type of learning rate scheduler (e.g., 'cosine' for cosine annealing)\n",
    "          \"learning_rate\":5e-4, # Initial learning rate\n",
    "          \"warmup_ratio\": 0.01, # Ratio of warmup steps to total training steps\n",
    "          \"weight_decay\": 0.01, # Weight decay coefficient for regularization\n",
    "          \"seed\": 1, # Random seed for reproducibility\n",
    "          \"load_best_model_at_end\": True, # Whether to load the best model at the end of training\n",
    "          \"report_to\": \"wandb\"} # Report the training progress to Weights & Biases\n",
    "\n",
    "# Create Namespace object with configuration\n",
    "args = Namespace(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "M07MnTwqJ34f"
   },
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "set_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "Zby2k2tQNYFG",
    "outputId": "74be8987-27c1-4fbb-b858-5e86633d1c76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20240209_114011-hahed7t5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/musicgen/pop909_musicgen/runs/hahed7t5' target=\"_blank\">easy-smoke-26</a></strong> to <a href='https://wandb.ai/musicgen/pop909_musicgen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/musicgen/pop909_musicgen' target=\"_blank\">https://wandb.ai/musicgen/pop909_musicgen</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/musicgen/pop909_musicgen/runs/hahed7t5' target=\"_blank\">https://wandb.ai/musicgen/pop909_musicgen/runs/hahed7t5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize and start a new WandB run for training\n",
    "run = wandb.init(project=wandb_project, job_type=\"training\", config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y-OMMfag8GEo"
   },
   "outputs": [],
   "source": [
    "# Code for converting token sequences to NoteSequences with audio-related information\n",
    "\n",
    "# Constants for note durations\n",
    "NOTE_LENGTH_16TH_120BPM = 0.25 * 60 / 120\n",
    "BAR_LENGTH_120BPM = 4.0 * 60 / 120\n",
    "\n",
    "def token_sequence_to_note_sequence(token_sequence, use_program=True, use_drums=True, instrument_mapper=None, only_piano=False):\n",
    "    \"\"\"\n",
    "    Convert a token sequence to a NoteSequence with audio-related information.\n",
    "    Args:\n",
    "        token_sequence (list or str): Token sequence representing musical information.\n",
    "        use_program (bool): Whether to use program information for instruments.\n",
    "        use_drums (bool): Whether to include drums in the output.\n",
    "        instrument_mapper (dict): Mapping of instrument names to MIDI program numbers.\n",
    "        only_piano (bool): Whether to include only piano instruments in the output.\n",
    "    Returns:\n",
    "        note_sequence (NoteSequence): Converted NoteSequence.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(token_sequence, str):\n",
    "        token_sequence = token_sequence.split()\n",
    "\n",
    "    note_sequence = empty_note_sequence()\n",
    "\n",
    "    # Render all notes.\n",
    "    current_program = 1\n",
    "    current_is_drum = False\n",
    "    current_instrument = 0\n",
    "    track_count = 0\n",
    "    current_bar_index = 0  # Initialize current_bar_index here\n",
    "    for token_index, token in enumerate(token_sequence):\n",
    "\n",
    "        if token == \"PIECE_START\":\n",
    "            pass\n",
    "        elif token == \"PIECE_END\":\n",
    "            print(\"The end.\")\n",
    "            break\n",
    "        elif token == \"TRACK_START\":\n",
    "            current_bar_index = 0\n",
    "            track_count += 1\n",
    "            pass\n",
    "        elif token == \"TRACK_END\":\n",
    "            pass\n",
    "        elif token == \"KEYS_START\":\n",
    "            pass\n",
    "        elif token == \"KEYS_END\":\n",
    "            pass\n",
    "        elif token.startswith(\"KEY=\"):\n",
    "            pass\n",
    "        elif token.startswith(\"INST\"):\n",
    "            instrument = token.split(\"=\")[-1]\n",
    "            if instrument != \"DRUMS\" and use_program:\n",
    "                if instrument_mapper is not None:\n",
    "                    if instrument in instrument_mapper:\n",
    "                        instrument = instrument_mapper[instrument]\n",
    "                current_program = int(instrument)\n",
    "                current_instrument = track_count\n",
    "                current_is_drum = False\n",
    "            if instrument == \"DRUMS\" and use_drums:\n",
    "                current_instrument = 0\n",
    "                current_program = 0\n",
    "                current_is_drum = True\n",
    "        elif token == \"BAR_START\":\n",
    "            current_time = current_bar_index * BAR_LENGTH_120BPM\n",
    "            current_notes = {}\n",
    "        elif token == \"BAR_END\":\n",
    "            current_bar_index += 1\n",
    "            pass\n",
    "        elif token.startswith(\"NOTE_ON\"):\n",
    "            pitch = int(token.split(\"=\")[-1])\n",
    "            note = note_sequence.notes.add()\n",
    "            note.start_time = current_time\n",
    "            note.end_time = current_time + 4 * NOTE_LENGTH_16TH_120BPM\n",
    "            note.pitch = pitch\n",
    "            note.instrument = current_instrument\n",
    "            note.program = current_program\n",
    "            note.velocity = 80\n",
    "            note.is_drum = current_is_drum\n",
    "            current_notes[pitch] = note\n",
    "        elif token.startswith(\"NOTE_OFF\"):\n",
    "            pitch = int(token.split(\"=\")[-1])\n",
    "            if pitch in current_notes:\n",
    "                note = current_notes[pitch]\n",
    "                note.end_time = current_time\n",
    "        elif token.startswith(\"TIME_DELTA\"):\n",
    "            delta = float(token.split(\"=\")[-1]) * NOTE_LENGTH_16TH_120BPM\n",
    "            current_time += delta\n",
    "        elif token.startswith(\"DENSITY=\"):\n",
    "            pass\n",
    "        elif token == \"[PAD]\":\n",
    "            pass\n",
    "        else:\n",
    "            #print(f\"Ignored token {token}.\")\n",
    "            pass\n",
    "\n",
    "    # Make the instruments right.\n",
    "    instruments_drums = []\n",
    "    for note in note_sequence.notes:\n",
    "        pair = [note.program, note.is_drum]\n",
    "        if pair not in instruments_drums:\n",
    "            instruments_drums += [pair]\n",
    "        note.instrument = instruments_drums.index(pair)\n",
    "\n",
    "    if only_piano:\n",
    "        for note in note_sequence.notes:\n",
    "            if not note.is_drum:\n",
    "                note.instrument = 0\n",
    "                note.program = 0\n",
    "\n",
    "    return note_sequence\n",
    "\n",
    "def empty_note_sequence(qpm=120.0, total_time=0.0):\n",
    "    \"\"\"\n",
    "    Create an empty NoteSequence with specified tempo and total time.\n",
    "    Args:\n",
    "        qpm (float): Quarter notes per minute (tempo).\n",
    "        total_time (float): Total time of the NoteSequence.\n",
    "    Returns:\n",
    "        note_sequence (NoteSequence): Empty NoteSequence.\n",
    "    \"\"\"\n",
    "    note_sequence = note_seq.protobuf.music_pb2.NoteSequence()\n",
    "    note_sequence.tempos.add().qpm = qpm\n",
    "    note_sequence.ticks_per_quarter = note_seq.constants.STANDARD_PPQ\n",
    "    note_sequence.total_time = total_time\n",
    "    return note_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "CYdVIUZ_7xWR"
   },
   "outputs": [],
   "source": [
    "# first create a custom trainer to log prediction distribution\n",
    "# Set the sample rate for audio processing\n",
    "SAMPLE_RATE=44100\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def evaluation_loop(\n",
    "        self,\n",
    "        dataloader,\n",
    "        description,\n",
    "        prediction_loss_only=None,\n",
    "        ignore_keys=None,\n",
    "        metric_key_prefix=\"eval\",\n",
    "    ):\n",
    "        # Import pyfluidsynth module here\n",
    "        import fluidsynth as fs\n",
    "\n",
    "        # Adjust FluidSynth polyphony\n",
    "        fluidsynth_settings = {\n",
    "            \"synth.polyphony\": 128,  # Increase polyphony to 128 voices\n",
    "            # Add more FluidSynth settings as needed\n",
    "        }\n",
    "\n",
    "        # Create a FluidSynth instance\n",
    "        fluidsynth_instance = fs.Synth()\n",
    "\n",
    "        # Initialize FluidSynth with modified settings\n",
    "        for setting, value in fluidsynth_settings.items():\n",
    "            fluidsynth_instance.setting(setting, value)\n",
    "\n",
    "\n",
    "        # Call super class method to get the eval outputs\n",
    "        eval_output = super().evaluation_loop(\n",
    "            dataloader,\n",
    "            description,\n",
    "            prediction_loss_only,\n",
    "            ignore_keys,\n",
    "            metric_key_prefix,\n",
    "        )\n",
    "\n",
    "         # Log the prediction distribution using `wandb.Histogram` method.\n",
    "        if wandb.run is not None:\n",
    "            # Encode a starting token to begin the generation\n",
    "            input_ids = self.tokenizer.encode(\"PIECE_START\", return_tensors=\"pt\").cuda()\n",
    "\n",
    "            # Generate more tokens for each voice\n",
    "            for voice_num in range(1, 5):\n",
    "                generated_ids = self.model.generate(\n",
    "                    input_ids,\n",
    "                    max_length=512,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.75, # Set temperature for sampling (higher values for more randomness, lower for more determinism)\n",
    "                    # top_p = 0.8, # Set top-p sampling parameters (nucleus sampling) to control diversity\n",
    "                    # top_k = 50, # Set top-k sampling parameters to restrict generation to the top-k most likely tokens\n",
    "                    eos_token_id=self.tokenizer.encode(\"TRACK_END\")[0]\n",
    "                )\n",
    "\n",
    "                # Decode the generated tokens into a token sequence\n",
    "                token_sequence = self.tokenizer.decode(generated_ids[0])\n",
    "\n",
    "                # Convert the token sequence into a NoteSequence\n",
    "                note_sequence = token_sequence_to_note_sequence(token_sequence)\n",
    "\n",
    "                # Synthesize the audio from the NoteSequence\n",
    "                synth = note_seq.fluidsynth\n",
    "                array_of_floats = synth(note_sequence, sample_rate=SAMPLE_RATE)\n",
    "\n",
    "                # Convert the float audio samples to int16 format\n",
    "                int16_data = note_seq.audio_io.float_samples_to_int16(array_of_floats)\n",
    "\n",
    "                # Log the generated audio using the wandb.Audio method\n",
    "                wandb.log({\"Generated_audio_voice_\" + str(voice_num): wandb.Audio(int16_data, SAMPLE_RATE)})\n",
    "\n",
    "        # Return the evaluation output\n",
    "        return eval_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JVsTKx3t-hLP"
   },
   "outputs": [],
   "source": [
    "# Create TrainingArguments object with training configuration\n",
    "train_args = TrainingArguments(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "D9hBshTJ9coM"
   },
   "outputs": [],
   "source": [
    " # Create training arguments\n",
    "train_args = TrainingArguments(**config)\n",
    "\n",
    "# Initialize the custom trainer for training the model\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=train_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "SEgCmFiz9v6S",
    "outputId": "b17a59aa-f4ae-48b2-9c6a-1e53a3132d19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='351' max='3742' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 351/3742 00:22 < 03:36, 15.69 it/s, Epoch 0.09/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='832' max='832' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [832/832 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1e61697fb735>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1555\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1556\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1920\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1922\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1923\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1924\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2269\u001b[0m                     \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2271\u001b[0;31m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3010\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3011\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   3012\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3013\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-db2ba5ca9640>\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;31m# Extract attention weights from the model for each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_attention_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# Log attention weights for each layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-d4239124bfa7>\u001b[0m in \u001b[0;36mextract_attention_weights\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Append the attention weights to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_attentions\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mattention_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_attentions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iomIVDkb8PeZ"
   },
   "outputs": [],
   "source": [
    "# call wandb.finish() to finish the run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bPkkleKq-zzL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1bf77370a9004b98988b53b11e1831c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": "center",
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "flex",
      "flex": null,
      "flex_flow": "column",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "50%"
     }
    },
    "226e708fa1bd4216b218e28d7746e39e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fd90eb4a07a430a96db8ec67ad1c739",
      "placeholder": "​",
      "style": "IPY_MODEL_6e309afb004d4e1fb62f2070ac1f2595",
      "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
     }
    },
    "3063bd81816b43139ab5899c7c31f2e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7578b3f8cbd45fb9b0d28ec35fd63b9",
       "IPY_MODEL_dae2d07d7e0c481a8add94341a848c12",
       "IPY_MODEL_485f1e54e47342359653f7573c2a772b"
      ],
      "layout": "IPY_MODEL_53eb9093a1754e789e43d911b102d57b"
     }
    },
    "35106fc0e5ca43a6a69381fb6547993b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Login",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_46ab4365aafe4928bfafc46393f9110e",
      "style": "IPY_MODEL_8a94055a3fcd4d43847780e422b2c882",
      "tooltip": ""
     }
    },
    "3ee28c7f4ce042bbb9086e67562f2c09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b006ce4b6efd48f58793e0af42c9270b",
       "IPY_MODEL_6b02d6ebfb894ceb86db9a2ed5715915",
       "IPY_MODEL_5140065dbda3426c84ae7e999936a49a"
      ],
      "layout": "IPY_MODEL_8778ca152a854fdda244f0960578b374"
     }
    },
    "46ab4365aafe4928bfafc46393f9110e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "485f1e54e47342359653f7573c2a772b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e18c5d05563544c195ed935f55a4a5fb",
      "placeholder": "​",
      "style": "IPY_MODEL_5e82d2d9b3c0431b8fdba40c2da0ca3d",
      "value": " 29930/29930 [00:07&lt;00:00, 3685.71 examples/s]"
     }
    },
    "5140065dbda3426c84ae7e999936a49a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff7bf6f6de044496acc585244b8a1dd5",
      "placeholder": "​",
      "style": "IPY_MODEL_9c6c00264ddf4446936058c232bad758",
      "value": " 3326/3326 [00:00&lt;00:00, 4363.57 examples/s]"
     }
    },
    "53eb9093a1754e789e43d911b102d57b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b8bafc47b114271a198304adbcaba54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5e82d2d9b3c0431b8fdba40c2da0ca3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5e899760c10440ea9de2a6d06b3c1bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6925f59ce901479ca15e50aee29f23ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "PasswordModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "PasswordModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "PasswordView",
      "continuous_update": true,
      "description": "Token:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_d422ea1cf318479892f6c74022144dd0",
      "placeholder": "​",
      "style": "IPY_MODEL_d48ab917e3dc4afd8207fc47691e4ef9",
      "value": ""
     }
    },
    "6a9c6787fe01465b80e3e7017fba2088": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b02d6ebfb894ceb86db9a2ed5715915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92ed3298b39c4a7191e8fa5caa667c6d",
      "max": 3326,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c82adea18c4f4364a1d686bd63f6b350",
      "value": 3326
     }
    },
    "6e309afb004d4e1fb62f2070ac1f2595": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6fd90eb4a07a430a96db8ec67ad1c739": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7946aa749ef14a418851c1e7ba0fe71b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8778ca152a854fdda244f0960578b374": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a94055a3fcd4d43847780e422b2c882": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "905b6c619b8240afb69bc9004d824c0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "920409b95bd543289b8ea0ea8f89473e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "CheckboxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "CheckboxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "CheckboxView",
      "description": "Add token as git credential?",
      "description_tooltip": null,
      "disabled": false,
      "indent": true,
      "layout": "IPY_MODEL_7946aa749ef14a418851c1e7ba0fe71b",
      "style": "IPY_MODEL_905b6c619b8240afb69bc9004d824c0f",
      "value": true
     }
    },
    "92c8b325541b463680d144974cf19568": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "92ed3298b39c4a7191e8fa5caa667c6d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c6c00264ddf4446936058c232bad758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7578b3f8cbd45fb9b0d28ec35fd63b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bac6cd8567cb4938ad66eeadf511a5f6",
      "placeholder": "​",
      "style": "IPY_MODEL_92c8b325541b463680d144974cf19568",
      "value": "Map: 100%"
     }
    },
    "af8cfd94abbe44e0bf9a08e8951bc09e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b006ce4b6efd48f58793e0af42c9270b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a9c6787fe01465b80e3e7017fba2088",
      "placeholder": "​",
      "style": "IPY_MODEL_5e899760c10440ea9de2a6d06b3c1bf7",
      "value": "Map: 100%"
     }
    },
    "bac6cd8567cb4938ad66eeadf511a5f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c82adea18c4f4364a1d686bd63f6b350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d31c9383bf7245999019beefa2030837": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d422ea1cf318479892f6c74022144dd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d48ab917e3dc4afd8207fc47691e4ef9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dae2d07d7e0c481a8add94341a848c12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af8cfd94abbe44e0bf9a08e8951bc09e",
      "max": 29930,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b8bafc47b114271a198304adbcaba54",
      "value": 29930
     }
    },
    "e18c5d05563544c195ed935f55a4a5fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1d358fc8ef5420aa0b15a6511cb7931": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fd8318b4015244e3ad2ddea4f2deda7c",
       "IPY_MODEL_6925f59ce901479ca15e50aee29f23ca",
       "IPY_MODEL_920409b95bd543289b8ea0ea8f89473e",
       "IPY_MODEL_35106fc0e5ca43a6a69381fb6547993b",
       "IPY_MODEL_226e708fa1bd4216b218e28d7746e39e"
      ],
      "layout": "IPY_MODEL_1bf77370a9004b98988b53b11e1831c8"
     }
    },
    "f32ddb2204964815a878e06b76d11939": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fd8318b4015244e3ad2ddea4f2deda7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d31c9383bf7245999019beefa2030837",
      "placeholder": "​",
      "style": "IPY_MODEL_f32ddb2204964815a878e06b76d11939",
      "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
     }
    },
    "ff7bf6f6de044496acc585244b8a1dd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
