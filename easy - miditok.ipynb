{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3dc257d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing MIDIs (to/tokens_noBPE): 100%|████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.04it/s]\n",
      "Performing data augmentation: 100%|██████████████████████████████████████████████████| 259/259 [00:11<00:00, 23.10it/s]\n",
      "Loading token files: 100%|████████████████████████████████████████████████████████| 1555/1555 [00:13<00:00, 116.02it/s]\n",
      "Applying BPE to dataset: 100%|████████████████████████████████████████████████████| 1555/1555 [00:11<00:00, 132.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "from miditoolkit import MidiFile\n",
    "from pathlib import Path\n",
    "\n",
    "# Creating a multitrack tokenizer configuration, read the doc to explore other parameters\n",
    "config = TokenizerConfig(num_velocities=16, use_chords=True, use_programs=True)\n",
    "tokenizer = REMI(config)\n",
    "\n",
    "# Loads a midi, converts to tokens, and back to a MIDI\n",
    "midi = MidiFile('C:/Users/naomi/Thesis/Thesis/Thesis-main/POP909/001/001.mid')\n",
    "tokens = tokenizer(midi)  # calling the tokenizer will automatically detect MIDIs, paths and tokens\n",
    "converted_back_midi = tokenizer(tokens)  # PyTorch / Tensorflow / Numpy tensors supported\n",
    "\n",
    "# Tokenize a whole dataset and save it at Json files\n",
    "midi_paths = list(Path(\"C:/Users/naomi/Thesis/Thesis/Thesis-main/POP909/001\").glob(\"**/*.mid\"))\n",
    "data_augmentation_offsets = [2, 1, 1]  # data augmentation on 2 pitch octaves, 1 velocity and 1 duration values\n",
    "tokenizer.tokenize_midi_dataset(midi_paths, Path(\"path\", \"to\", \"tokens_noBPE\"),\n",
    "                                data_augment_offsets=data_augmentation_offsets)\n",
    "\n",
    "# Constructs the vocabulary with BPE, from the token files\n",
    "tokenizer.learn_bpe(\n",
    "    vocab_size=10000,\n",
    "    tokens_paths=list(Path(\"path\", \"to\", \"tokens_noBPE\").glob(\"**/*.json\")),\n",
    "    start_from_empty_voc=False,\n",
    ")\n",
    "\n",
    "# Saving our tokenizer, to retrieve it back later with the load_params method\n",
    "tokenizer.save_params(Path(\"path\", \"to\", \"save\", \"tokenizer.json\"))\n",
    "# And pushing it to the Hugging Face hub (you can download it back with .from_pretrained)\n",
    "tokenizer.push_to_hub(\"aimusicgen/easy-miditok\", private=True, token=\"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\")\n",
    "\n",
    "# Applies BPE to the previous tokens\n",
    "tokenizer.apply_bpe_to_dataset(Path('path', 'to', 'tokens_noBPE'), Path('path', 'to', 'tokens_BPE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f020649",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
